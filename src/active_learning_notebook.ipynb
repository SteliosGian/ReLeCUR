{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "import pandas as pd\n",
    "import math as math\n",
    "import random\n",
    "import numpy as np\n",
    "import collections\n",
    "import random\n",
    "import csv\n",
    "import turicreate as gl\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre>Finished parsing file /Users/steliosgiannikis/dev/personal/ReLeCUR/src/useritemmatrix.csv</pre>"
      ],
      "text/plain": [
       "Finished parsing file /Users/steliosgiannikis/dev/personal/ReLeCUR/src/useritemmatrix.csv"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Parsing completed. Parsed 100 lines in 0.582684 secs.</pre>"
      ],
      "text/plain": [
       "Parsing completed. Parsed 100 lines in 0.582684 secs."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------\n",
      "Inferred types from first 100 line(s) of file as \n",
      "column_type_hints=[int,int,str,int]\n",
      "If parsing fails due to incorrect types, you can correct\n",
      "the inferred type list above and pass it to read_csv in\n",
      "the column_type_hints argument\n",
      "------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre>Read 700684 lines. Lines per second: 780546</pre>"
      ],
      "text/plain": [
       "Read 700684 lines. Lines per second: 780546"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Finished parsing file /Users/steliosgiannikis/dev/personal/ReLeCUR/src/useritemmatrix.csv</pre>"
      ],
      "text/plain": [
       "Finished parsing file /Users/steliosgiannikis/dev/personal/ReLeCUR/src/useritemmatrix.csv"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Parsing completed. Parsed 2563878 lines in 2.11481 secs.</pre>"
      ],
      "text/plain": [
       "Parsing completed. Parsed 2563878 lines in 2.11481 secs."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# load dataset\n",
    "\n",
    "data = gl.SFrame.read_csv(\"useritemmatrix.csv\",header=True,delimiter=',')\n",
    "data.remove_column(\"X1\")\n",
    "# transform dataset from graphlab SFrame to pandas DataFrame\n",
    "data_pd = gl.SFrame.to_dataframe(data)\n",
    "data_pd[\"itemId\"] = data_pd[\"itemId\"].astype(\"category\").cat.codes\n",
    "# TRAINING SET PARTITIONING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selecting 139605 cold user(s)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/steliosgiannikis/miniconda3/envs/relecur/lib/python3.6/site-packages/ipykernel_launcher.py:12: FutureWarning: get_value is deprecated and will be removed in a future release. Please use .at[] or .iat[] accessors instead\n",
      "  if sys.path[0] == '':\n"
     ]
    }
   ],
   "source": [
    "# checking users who have many purchases\n",
    "user_freq_df = pd.DataFrame.from_dict(collections.Counter(data_pd['userId']),orient='index').reset_index()\n",
    "user_freq_df = user_freq_df.rename(columns={'index':'userId', 0:'freq'})\n",
    "\n",
    "# percentage of total number of users to set as cold user\n",
    "perc_cold_users = 0.25\n",
    "nr_of_cold_users = int(math.floor(len(user_freq_df)*perc_cold_users))\n",
    "\n",
    "# select the [nr_of_cold_users] with the highest number of interactions\n",
    "cold_users = user_freq_df.sample(nr_of_cold_users,random_state=1)\n",
    "cold_users = cold_users.get_value(index=range(0,(nr_of_cold_users)),col=0,takeable=True)\n",
    "\n",
    "print('Selecting ' + str(nr_of_cold_users) + ' cold user(s)')\n",
    "\n",
    "\n",
    "# SETTINGS FOR SHOWN ITEMS (ranking lengths and item frequency threshold) AND COMPUTING THE GINI, ENTROPY AND POPENT SCORES FOR THE ITEMS\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute purchase purchase/return frequency per item\n",
    "item_freq_counter = collections.Counter(data_pd['itemId'])\n",
    "item_freq_df = pd.DataFrame.from_dict(item_freq_counter,orient='index').reset_index()\n",
    "item_freq_df = item_freq_df.rename(columns={'index':'itemId', 0:'freq'})\n",
    "\n",
    "# produce list of items which are at least interacted with [threshold_item] times\n",
    "threshold_item = 10\n",
    "threshold_item_df = item_freq_df[item_freq_df['freq']>=threshold_item]['itemId']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GINI SCORE\n",
    "# function to compute Gini\n",
    "def gini(labels):\n",
    "    n_labels = len(labels)\n",
    "\n",
    "    if n_labels <= 1:\n",
    "        return 0\n",
    "\n",
    "    counts = np.bincount(labels)\n",
    "    probs = counts / n_labels\n",
    "    n_classes = np.count_nonzero(probs)\n",
    "\n",
    "    if n_classes <= 1:\n",
    "        return 0\n",
    "\n",
    "    gini = 0.\n",
    "    \n",
    "    sum_probs = 0\n",
    "    \n",
    "    for iterator in probs:\n",
    "        sum_probs += iterator * iterator\n",
    "\n",
    "    gini = 1 - sum_probs\n",
    "    return gini\n",
    "\n",
    "unique_itemId = pd.Series(threshold_item_df)\n",
    "gini_list = np.zeros(shape=(len(unique_itemId),2))\n",
    "j = 0\n",
    "\n",
    "# loop over all itemId's and compute the Gini for each item\n",
    "for i in unique_itemId:\n",
    "    item_i_df = data_pd[data_pd['itemId'] == i]\n",
    "    gini_list[j] = [i,gini(item_i_df['interaction'])]\n",
    "    j += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computed Gini scores for all items\n"
     ]
    }
   ],
   "source": [
    "# transform to pandas DataFrame\n",
    "to_df = {'itemId' : gini_list[:,0],'gini' : gini_list[:,1]}\n",
    "gini_items_df = pd.DataFrame(to_df)\n",
    "gini_items_df.sort_values(by='gini',inplace=True,ascending=False)\n",
    "\n",
    "\n",
    "del gini_list\n",
    "\n",
    "print('Computed Gini scores for all items')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  ERROR SCORE\n",
    "# function to compute misclassification error\n",
    "def error(labels):\n",
    "    n_labels = len(labels)\n",
    "\n",
    "    if n_labels <= 1:\n",
    "        return 0\n",
    "\n",
    "    counts = np.bincount(labels)\n",
    "    probs = counts / n_labels\n",
    "    n_classes = np.count_nonzero(probs)\n",
    "\n",
    "    if n_classes <= 1:\n",
    "        return 0\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "    error = 1 - probs.max()\n",
    "    return error\n",
    "\n",
    "unique_itemId = pd.Series(threshold_item_df)\n",
    "error_list = np.zeros(shape=(len(unique_itemId),2))\n",
    "j = 0\n",
    "\n",
    "# loop over all itemId's and compute the error for each item\n",
    "for i in unique_itemId:\n",
    "    item_i_df = data_pd[data_pd['itemId'] == i]\n",
    "    error_list[j] = [i,error(item_i_df['interaction'])]\n",
    "    j += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computed error scores for all items\n"
     ]
    }
   ],
   "source": [
    "# transform to pandas DataFrame\n",
    "to_df = {'itemId' : error_list[:,0],'error' : error_list[:,1]}\n",
    "error_items_df = pd.DataFrame(to_df)\n",
    "error_items_df.sort_values(by='error',inplace=True,ascending=False)\n",
    "\n",
    "del error_list\n",
    "\n",
    "print('Computed error scores for all items')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computed variance scores for all items\n"
     ]
    }
   ],
   "source": [
    "# VARIANCE SCORE\n",
    "# function to compute variance\n",
    "def variance(labels, users):\n",
    "    n_labels = len(labels)\n",
    "    users_u = users.nunique()\n",
    "    \n",
    "    if n_labels <= 1:\n",
    "        return 0\n",
    "    \n",
    "    counts = np.bincount(labels)\n",
    "    probs = counts / n_labels\n",
    "    n_classes = np.count_nonzero(probs)\n",
    "\n",
    "    if n_classes <= 1:\n",
    "        return 0\n",
    "    \n",
    "    var = 0.\n",
    "\n",
    "    for r_ui in labels:\n",
    "            var += ((r_ui - np.mean(labels))**2)\n",
    "        \n",
    "    variance = var/users_u\n",
    "\n",
    "    return variance\n",
    "\n",
    "unique_itemId = pd.Series(threshold_item_df)\n",
    "variance_list = np.zeros(shape=(len(unique_itemId),2))\n",
    "j = 0\n",
    "\n",
    "# loop over all itemId's and compute the variance for each item\n",
    "for i in unique_itemId:\n",
    "    item_i_df = data_pd[(data_pd['itemId'] == i)]\n",
    "    variance_list[j] = [i,variance(item_i_df['interaction'], item_i_df[\"userId\"])]\n",
    "    j += 1\n",
    "    \n",
    "# transform to pandas DataFrame\n",
    "to_df = {'itemId' : variance_list[:,0],'variance' : variance_list[:,1]}\n",
    "variance_items_df = pd.DataFrame(to_df)\n",
    "variance_items_df.sort_values(by='variance',inplace=True,ascending=False)\n",
    "\n",
    "del variance_list\n",
    "\n",
    "print('Computed variance scores for all items')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ENTROPY SCORE\n",
    "# function to compute entropy\n",
    "def entropy(labels):\n",
    "    n_labels = len(labels)\n",
    "\n",
    "    if n_labels <= 1:\n",
    "        return 0\n",
    "\n",
    "    counts = np.bincount(labels)\n",
    "    probs = counts / n_labels\n",
    "    n_classes = np.count_nonzero(probs)\n",
    "\n",
    "    if n_classes <= 1:\n",
    "        return 0\n",
    "\n",
    "    ent = 0.\n",
    "\n",
    "    for iterator in probs:\n",
    "        ent -= iterator * np.log2(iterator)\n",
    "\n",
    "    return ent\n",
    "\n",
    "unique_itemId = pd.Series(threshold_item_df)\n",
    "entropy_list = np.zeros(shape=(len(unique_itemId),2))\n",
    "j = 0\n",
    "\n",
    "# loop over all itemId's and compute the entropy for each item\n",
    "for i in unique_itemId:\n",
    "    item_i_df = data_pd[data_pd['itemId'] == i]\n",
    "    entropy_list[j] = [i,entropy(item_i_df['interaction'])]\n",
    "    j += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computed entropy scores for all items\n"
     ]
    }
   ],
   "source": [
    "# transform to pandas DataFrame\n",
    "to_df = {'itemId' : entropy_list[:,0],'entropy' : entropy_list[:,1]}\n",
    "ent_items_df = pd.DataFrame(to_df)\n",
    "ent_items_df.sort_values(by='entropy',inplace=True,ascending=False)\n",
    "\n",
    "del entropy_list\n",
    "\n",
    "print('Computed entropy scores for all items')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare item purchase counts for merging\n",
    "item_freq_df.sort_values(by='itemId',inplace=True)\n",
    "item_freq_df.set_index(keys='itemId',inplace=True)\n",
    "item_freq_df['freq'] = pd.to_numeric(item_freq_df['freq'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# POPGINI SCORE\n",
    "# prepare item gini scores for merging\n",
    "gini_items_df2 = gini_items_df.sort_values(by='itemId')\n",
    "gini_items_df2.set_index(keys='itemId',inplace=True)\n",
    "\n",
    "# merge frequencies and entropies\n",
    "popgini_items_df = pd.concat([item_freq_df,gini_items_df2],axis=1,join='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computed PopGini scores for all items\n"
     ]
    }
   ],
   "source": [
    "# set weights for the popgini score\n",
    "weight_popularity = 0.9\n",
    "weight_gini = 1\n",
    "\n",
    "# compute popgini score\n",
    "popgini_items_df['popgini'] = weight_popularity*np.log10(popgini_items_df['freq'])+weight_gini*popgini_items_df['gini']\n",
    "popgini_items_df.sort_values(by='popgini',inplace=True,ascending=False)\n",
    "\n",
    "print('Computed PopGini scores for all items')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# POPENT SCORE\n",
    "# prepare item entropies for merging\n",
    "ent_items_df2 = ent_items_df.sort_values(by='itemId')\n",
    "ent_items_df2.set_index(keys='itemId',inplace=True)\n",
    "\n",
    "# merge frequencies and entropies\n",
    "popent_items_df = pd.concat([item_freq_df,ent_items_df2],axis=1,join='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computed PopEnt scores for all items\n"
     ]
    }
   ],
   "source": [
    "# set weights for the popent score\n",
    "weight_popularity = 0.9\n",
    "weight_entropy = 1\n",
    "\n",
    "# compute popent score\n",
    "popent_items_df['popent'] = weight_popularity*np.log10(popent_items_df['freq'])+weight_entropy*popent_items_df['entropy']\n",
    "popent_items_df.sort_values(by='popent',inplace=True,ascending=False)\n",
    "\n",
    "print('Computed PopEnt scores for all items')\n",
    "\n",
    "\n",
    "# POPENT SCORE WEIGHT OPTIMIZATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computed poperror scores for all items\n"
     ]
    }
   ],
   "source": [
    "# POPERROR SCORE\n",
    "# prepare item error for merging\n",
    "error_items_df2 = error_items_df.sort_values(by='itemId')\n",
    "error_items_df2.set_index(keys='itemId',inplace=True)\n",
    "\n",
    "# merge frequencies and errors\n",
    "poperror_items_df = pd.concat([item_freq_df,error_items_df2],axis=1,join='inner')\n",
    "\n",
    "# set weights for the poperror score\n",
    "weight_popularity = 0.9\n",
    "weight_error = 1\n",
    "\n",
    "# compute poperror score\n",
    "poperror_items_df['error'] = weight_popularity*np.log10(poperror_items_df['freq'])+weight_error*poperror_items_df['error']\n",
    "poperror_items_df.sort_values(by='error',inplace=True,ascending=False)\n",
    "\n",
    "print('Computed poperror scores for all items')\n",
    "\n",
    "\n",
    "# POPERROR SCORE WEIGHT OPTIMIZATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computed popvar scores for all items\n"
     ]
    }
   ],
   "source": [
    "# POPVAR SCORE\n",
    "# prepare item variance for merging\n",
    "variance_items_df2 = variance_items_df.sort_values(by='itemId')\n",
    "variance_items_df2.set_index(keys='itemId',inplace=True)\n",
    "\n",
    "# merge frequencies and variances\n",
    "popvar_items_df = pd.concat([item_freq_df,variance_items_df2],axis=1,join='inner')\n",
    "\n",
    "# set weights for the popvar score\n",
    "weight_popularity = 0.9\n",
    "weight_variance = 1\n",
    "\n",
    "# compute popvar score\n",
    "popvar_items_df['variance'] = weight_popularity*np.log10(popvar_items_df['freq'])+weight_variance*popvar_items_df['variance']\n",
    "popvar_items_df.sort_values(by='variance',inplace=True,ascending=False)\n",
    "\n",
    "print('Computed popvar scores for all items')\n",
    "\n",
    "\n",
    "# POPVAR SCORE WEIGHT OPTIMIZATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filename = 'weights_popent_final_new.csv'\n",
    "# csvfile = open(filename, 'w+')\n",
    "# writer = csv.writer(csvfile, delimiter=',')\n",
    "# writer.writerow(['Ranking strategy','Nr. of shown items','Nr. of cold users','RMSE','Weight popularity','Weight entropy'])\n",
    "\n",
    "# # start k and l for loop here\n",
    "\n",
    "# weight_pop_list = [0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,1]\n",
    "# weight_ent_list = [0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,1]\n",
    "\n",
    "# nr_of_shown_items_list = [10,100,1000,10000]\n",
    "\n",
    "# for k in weight_pop_list:\n",
    "#     for l in weight_ent_list:\n",
    "        \n",
    "#         # set weights for the popent score\n",
    "#         weight_popularity = k\n",
    "#         weight_entropy = l\n",
    "#         # compute popent score\n",
    "#         popent_items_df['popent'] = weight_popularity*np.log10(popent_items_df['freq'])+weight_entropy*popent_items_df['entropy']\n",
    "#         popent_items_df.sort_values(by='popent',inplace=True,ascending=False)\n",
    "\n",
    "#         print 'Computed popent scores for all items'\n",
    "#         print k \n",
    "#         print l\n",
    "\n",
    "# # start m for loop here\n",
    "\n",
    "#         for m in nr_of_shown_items_list:\n",
    "#             # set the number of items to show to the cold user\n",
    "#             nr_of_shown_items = m\n",
    "#             print 'Number of items shown to the cold user(s): ' + str(nr_of_shown_items)\n",
    "\n",
    "#             # POPENT STRATEGY\n",
    "#             # select the top [nr_of_shown_items] items (which are interacted with at least [threshold_item] times) with largest popent score\n",
    "#             popent_items = popent_items_df.head(nr_of_shown_items)\n",
    "#             popent_items_final = np.array(popent_items.index.values, dtype=np.int64)\n",
    "#             print 'Computed ranking using popent strategy'\n",
    "\n",
    "#             # hyperparameter ranges\n",
    "#             # optimal hyperparameters\n",
    "#             # num_factors\n",
    "#             i = 200\n",
    "#             # regularization\n",
    "#             j = '1e-06'\n",
    "#             # linear_regularization\n",
    "#             h = '1e-07'\n",
    "#             # number of shown items\n",
    "#             number_of_shown_items = str(nr_of_shown_items)\n",
    "\n",
    "#             print 'Computing results'\n",
    "\n",
    "#             # POPENT STRATEGY\n",
    "#             ranking_strategy = 'PopEnt strategy'\n",
    "#             # model is trained on all user item pairs of the warm users and the user item pairs of the cold user with the shown items (if the cold user has interacted with the shown items)\n",
    "#             train_pd = data_pd[(~data_pd.userId.isin(cold_users)) | (data_pd.itemId.isin(popent_items_final))]\n",
    "#             # cold user(s) that have interacted with one or more of the shown items (if a cold user has not interacted with any of the shown items, it is not included in the test set)\n",
    "#             cold_users_interacted = np.array(data_pd[(data_pd.userId.isin(cold_users)) & (data_pd.itemId.isin(popent_items_final))]['userId'])\n",
    "#             test_pd = data_pd[(data_pd.userId.isin(cold_users_interacted)) & (~data_pd.itemId.isin(popent_items_final))]\n",
    "#             train = gl.SFrame(train_pd)\n",
    "#             test = gl.SFrame(test_pd)\n",
    "\n",
    "#             model = gl.factorization_recommender.create(train,user_id='userId',item_id='itemId',target='interaction',num_factors=i,regularization=j,linear_regularization=h,binary_target=True,max_iterations=50,random_seed=1,verbose=False)\n",
    "\n",
    "#             print 'Rec sys built for popent strategy'\n",
    "\n",
    "#             rmse = model.evaluate_rmse(test,target='interaction')[\"rmse_overall\"]\n",
    "\n",
    "#             print 'RMSE computed for popent strategy'\n",
    "\n",
    "#             writer.writerow([ranking_strategy,number_of_shown_items,nr_of_cold_users,rmse,k,l])\n",
    "            \n",
    "#             print 'Finished computing results'\n",
    "\n",
    "# csvfile.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of items shown to the cold user(s): 10\n",
      "Computed ranking using random strategy\n"
     ]
    }
   ],
   "source": [
    "# set the number of items to show to the cold user\n",
    "# !!! in final version, construct a loop here (and test for different number of items shown to the cold user(s))\n",
    "\n",
    "nr_of_shown_items = 10\n",
    "print('Number of items shown to the cold user(s): ' + str(nr_of_shown_items))\n",
    "\n",
    "# RANDOM STRATEGY\n",
    "# select [nr_of_shown_items] items (which are interacted with at least [threshold_item] times) at random\n",
    "random_items = random.sample(list(threshold_item_df),nr_of_shown_items)\n",
    "random_items = np.array(random_items,dtype='int64')\n",
    "\n",
    "print('Computed ranking using random strategy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computed ranking using popularity strategy\n"
     ]
    }
   ],
   "source": [
    "# POPULARITY STRATEGY\n",
    "# select the top [nr_of_shown_items] items (which are interacted with at least [threshold_item] times) sorted by popularity (purchase/return frequency)\n",
    "pop_items = item_freq_counter.most_common(nr_of_shown_items)\n",
    "pop_items = [x[0] for x in pop_items]\n",
    "pop_items = np.array(pop_items,dtype='int64')\n",
    "print('Computed ranking using popularity strategy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computed ranking using Gini strategy\n"
     ]
    }
   ],
   "source": [
    "# GINI STRATEGY\n",
    "# select the top [nr_of_shown_items] items (which are interacted with at least [threshold_item] times) with largest Gini\n",
    "gini_items = gini_items_df.head(nr_of_shown_items)['itemId']\n",
    "gini_items = np.array(gini_items,dtype=np.int64)\n",
    "print('Computed ranking using Gini strategy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computed ranking using entropy strategy\n"
     ]
    }
   ],
   "source": [
    "# ENTROPY STRATEGY\n",
    "# select the top [nr_of_shown_items] items (which are interacted with at least [threshold_item] times) with largest entropy\n",
    "ent_items = ent_items_df.head(nr_of_shown_items)['itemId']\n",
    "ent_items = np.array(ent_items,dtype=np.int64)\n",
    "print('Computed ranking using entropy strategy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computed ranking using popgini strategy\n"
     ]
    }
   ],
   "source": [
    "# POPGINI STRATEGY\n",
    "# select the top [nr_of_shown_items] items (which are interacted with at least [threshold_item] times) with largest popgini score\n",
    "popgini_items = popgini_items_df.head(nr_of_shown_items)\n",
    "popgini_items = np.array(popgini_items.index.values, dtype=np.int64)\n",
    "print('Computed ranking using popgini strategy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computed ranking using popent strategy\n"
     ]
    }
   ],
   "source": [
    "# POPENT STRATEGY\n",
    "# select the top [nr_of_shown_items] items (which are interacted with at least [threshold_item] times) with largest popent score\n",
    "popent_items = popent_items_df.head(nr_of_shown_items)\n",
    "popent_items = np.array(popent_items.index.values, dtype=np.int64)\n",
    "print('Computed ranking using popent strategy')\n",
    "\n",
    "\n",
    "# COMPUTING THE RESULTS FOR EACH RANKING STRATEGY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computed ranking using error strategy\n"
     ]
    }
   ],
   "source": [
    "# ERROR STRATEGY\n",
    "# select the top [nr_of_shown_items] items (which are interacted with at least [threshold_item] times) with largest error score\n",
    "error_items = error_items_df.head(nr_of_shown_items)[\"itemId\"]\n",
    "error_items = np.array(error_items, dtype=np.int64)\n",
    "print('Computed ranking using error strategy')\n",
    "\n",
    "\n",
    "\n",
    "# COMPUTING THE RESULTS FOR EACH RANKING STRATEGY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computed ranking using variance strategy\n"
     ]
    }
   ],
   "source": [
    "# VARIANCE STRATEGY\n",
    "# select the top [nr_of_shown_items] items (which are interacted with at least [threshold_item] times) with largest variance score\n",
    "variance_items = variance_items_df.head(nr_of_shown_items)[\"itemId\"]\n",
    "variance_items = np.array(variance_items, dtype=np.int64)\n",
    "print('Computed ranking using variance strategy')\n",
    "\n",
    "\n",
    "# COMPUTING THE RESULTS FOR EACH RANKING STRATEGY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computed ranking using poperror strategy\n"
     ]
    }
   ],
   "source": [
    "# POPERROR STRATEGY\n",
    "# select the top [nr_of_shown_items] items (which are interacted with at least [threshold_item] times) with largest popent score\n",
    "poperror_items = poperror_items_df.head(nr_of_shown_items)\n",
    "poperror_items = np.array(poperror_items.index.values, dtype=np.int64)\n",
    "print('Computed ranking using poperror strategy')\n",
    "\n",
    "\n",
    "# COMPUTING THE RESULTS FOR EACH RANKING STRATEGY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computed ranking using popvar strategy\n"
     ]
    }
   ],
   "source": [
    "# POPVAR STRATEGY\n",
    "# select the top [nr_of_shown_items] items (which are interacted with at least [threshold_item] times) with largest popent score\n",
    "popvar_items = popvar_items_df.head(nr_of_shown_items)\n",
    "popvar_items = np.array(popvar_items.index.values, dtype=np.int64)\n",
    "print('Computed ranking using popvar strategy')\n",
    "\n",
    "\n",
    "# COMPUTING THE RESULTS FOR EACH RANKING STRATEGY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing results\n"
     ]
    }
   ],
   "source": [
    "# hyperparameter ranges\n",
    "# optimal hyperparameters\n",
    "# num_factors\n",
    "i = 200\n",
    "# regularization\n",
    "j = '1e-06'\n",
    "# linear_regularization\n",
    "h = '1e-07'\n",
    "# number of shown items\n",
    "number_of_shown_items = str(nr_of_shown_items)\n",
    "\n",
    "print('Computing results')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rec sys built for random strategy\n",
      "RMSE computed for random strategy\n"
     ]
    }
   ],
   "source": [
    "# RANDOM STRATEGY\n",
    "ranking_strategy = 'Random strategy'\n",
    "# model is trained on all user item pairs of the warm users and the user item pairs of the cold user with the shown items (if the cold user has interacted with the shown items)\n",
    "train_pd = data_pd[(~data_pd.userId.isin(cold_users)) | (data_pd.itemId.isin(random_items))]\n",
    "\n",
    "# cold user(s) that have interacted with one or more of the shown items (if a cold user has not interacted with any of the shown items, it is not included in the test set)\n",
    "cold_users_interacted = np.array(data_pd[(data_pd.userId.isin(cold_users)) & (data_pd.itemId.isin(random_items))]['userId'])\n",
    "test_pd = data_pd[(data_pd.userId.isin(cold_users_interacted)) & (~data_pd.itemId.isin(random_items))]\n",
    "\n",
    "train = gl.SFrame(train_pd)\n",
    "test = gl.SFrame(test_pd)\n",
    "\n",
    "model = gl.factorization_recommender.create(train,user_id='userId',item_id='itemId',target='interaction',num_factors=i,regularization=j,linear_regularization=h,binary_target=True,max_iterations=50,random_seed=1,verbose=False)\n",
    "\n",
    "print('Rec sys built for random strategy')\n",
    "\n",
    "rmse = model.evaluate_rmse(test,target='interaction')[\"rmse_overall\"]\n",
    "\n",
    "print('RMSE computed for random strategy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rec sys built for popularity strategy\n",
      "RMSE computed for popularity strategy\n"
     ]
    }
   ],
   "source": [
    "filename = str('final_results_shown_items_' + number_of_shown_items + '.csv')\n",
    "csvfile = open(filename, 'w+')\n",
    "writer = csv.writer(csvfile, delimiter=',')\n",
    "writer.writerow(['Ranking strategy','Nr. of shown items','Nr. of cold users','RMSE'])\n",
    "writer.writerow([ranking_strategy,number_of_shown_items,nr_of_cold_users,rmse])\n",
    "\n",
    "# POPULARITY STRATEGY\n",
    "ranking_strategy = 'Popularity strategy'\n",
    "# model is trained on all user item pairs of the warm users and the user item pairs of the cold user with the shown items (if the cold user has interacted with the shown items)\n",
    "train_pd = data_pd[(~data_pd.userId.isin(cold_users)) | (data_pd.itemId.isin(pop_items))]\n",
    "\n",
    "# cold user(s) that have interacted with one or more of the shown items (if a cold user has not interacted with any of the shown items, it is not included in the test set)\n",
    "cold_users_interacted = np.array(data_pd[(data_pd.userId.isin(cold_users)) & (data_pd.itemId.isin(pop_items))]['userId'])\n",
    "test_pd = data_pd[(data_pd.userId.isin(cold_users_interacted)) & (~data_pd.itemId.isin(pop_items))]\n",
    "\n",
    "train = gl.SFrame(train_pd)\n",
    "test = gl.SFrame(test_pd)\n",
    "\n",
    "model = gl.factorization_recommender.create(train,user_id='userId',item_id='itemId',target='interaction',num_factors=i,regularization=j,linear_regularization=h,binary_target=True,max_iterations=50,random_seed=1,verbose=False)\n",
    "\n",
    "print('Rec sys built for popularity strategy')\n",
    "\n",
    "rmse = model.evaluate_rmse(test,target='interaction')[\"rmse_overall\"]\n",
    "\n",
    "print('RMSE computed for popularity strategy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rec sys built for Gini strategy\n",
      "RMSE computed for Gini strategy\n"
     ]
    }
   ],
   "source": [
    "writer.writerow([ranking_strategy,number_of_shown_items,nr_of_cold_users,rmse])\n",
    "\n",
    "\n",
    "# GINI STRATEGY\n",
    "ranking_strategy = 'Gini strategy'\n",
    "# model is trained on all user item pairs of the warm users and the user item pairs of the cold user with the shown items (if the cold user has interacted with the shown items)\n",
    "train_pd = data_pd[(~data_pd.userId.isin(cold_users)) | (data_pd.itemId.isin(gini_items))]\n",
    "# cold user(s) that have interacted with one or more of the shown items (if a cold user has not interacted with any of the shown items, it is not included in the test set)\n",
    "cold_users_interacted = np.array(data_pd[(data_pd.userId.isin(cold_users)) & (data_pd.itemId.isin(gini_items))]['userId'])\n",
    "test_pd = data_pd[(data_pd.userId.isin(cold_users_interacted)) & (~data_pd.itemId.isin(gini_items))]\n",
    "train = gl.SFrame(train_pd)\n",
    "test = gl.SFrame(test_pd)\n",
    "\n",
    "model = gl.factorization_recommender.create(train,user_id='userId',item_id='itemId',target='interaction',num_factors=i,regularization=j,linear_regularization=h,binary_target=True,max_iterations=50,random_seed=1,verbose=False)\n",
    "\n",
    "print('Rec sys built for Gini strategy')\n",
    "\n",
    "rmse = model.evaluate_rmse(test,target='interaction')[\"rmse_overall\"]\n",
    "\n",
    "print('RMSE computed for Gini strategy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rec sys built for entropy strategy\n",
      "RMSE computed for entropy strategy\n"
     ]
    }
   ],
   "source": [
    "writer.writerow([ranking_strategy,number_of_shown_items,nr_of_cold_users,rmse])\n",
    "\n",
    "\n",
    "# ENTROPY STRATEGY\n",
    "ranking_strategy = 'Entropy strategy'\n",
    "# model is trained on all user item pairs of the warm users and the user item pairs of the cold user with the shown items (if the cold user has interacted with the shown items)\n",
    "train_pd = data_pd[(~data_pd.userId.isin(cold_users)) | (data_pd.itemId.isin(ent_items))]\n",
    "# cold user(s) that have interacted with one or more of the shown items (if a cold user has not interacted with any of the shown items, it is not included in the test set)\n",
    "cold_users_interacted = np.array(data_pd[(data_pd.userId.isin(cold_users)) & (data_pd.itemId.isin(ent_items))]['userId'])\n",
    "test_pd = data_pd[(data_pd.userId.isin(cold_users_interacted)) & (~data_pd.itemId.isin(ent_items))]\n",
    "train = gl.SFrame(train_pd)\n",
    "test = gl.SFrame(test_pd)\n",
    "\n",
    "model = gl.factorization_recommender.create(train,user_id='userId',item_id='itemId',target='interaction',num_factors=i,regularization=j,linear_regularization=h,binary_target=True,max_iterations=50,random_seed=1,verbose=False)\n",
    "\n",
    "print('Rec sys built for entropy strategy')\n",
    "\n",
    "rmse = model.evaluate_rmse(test,target='interaction')[\"rmse_overall\"]\n",
    "\n",
    "print('RMSE computed for entropy strategy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rec sys built for popgini strategy\n",
      "RMSE computed for popgini strategy\n"
     ]
    }
   ],
   "source": [
    "writer.writerow([ranking_strategy,number_of_shown_items,nr_of_cold_users,rmse])\n",
    "\n",
    "\n",
    "# POPGINI STRATEGY\n",
    "ranking_strategy = 'PopGini strategy'\n",
    "# model is trained on all user item pairs of the warm users and the user item pairs of the cold user with the shown items (if the cold user has interacted with the shown items)\n",
    "train_pd = data_pd[(~data_pd.userId.isin(cold_users)) | (data_pd.itemId.isin(popgini_items))]\n",
    "# cold user(s) that have interacted with one or more of the shown items (if a cold user has not interacted with any of the shown items, it is not included in the test set)\n",
    "cold_users_interacted = np.array(data_pd[(data_pd.userId.isin(cold_users)) & (data_pd.itemId.isin(popgini_items))]['userId'])\n",
    "test_pd = data_pd[(data_pd.userId.isin(cold_users_interacted)) & (~data_pd.itemId.isin(popgini_items))]\n",
    "train = gl.SFrame(train_pd)\n",
    "test = gl.SFrame(test_pd)\n",
    "\n",
    "model = gl.factorization_recommender.create(train,user_id='userId',item_id='itemId',target='interaction',num_factors=i,regularization=j,linear_regularization=h,binary_target=True,max_iterations=50,random_seed=1,verbose=False)\n",
    "\n",
    "print('Rec sys built for popgini strategy')\n",
    "\n",
    "rmse = model.evaluate_rmse(test,target='interaction')[\"rmse_overall\"]\n",
    "\n",
    "print('RMSE computed for popgini strategy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rec sys built for popent strategy\n",
      "RMSE computed for popent strategy\n"
     ]
    }
   ],
   "source": [
    "writer.writerow([ranking_strategy,number_of_shown_items,nr_of_cold_users,rmse])\n",
    "\n",
    "\n",
    "# POPENT STRATEGY\n",
    "ranking_strategy = 'PopEnt strategy'\n",
    "# model is trained on all user item pairs of the warm users and the user item pairs of the cold user with the shown items (if the cold user has interacted with the shown items)\n",
    "train_pd = data_pd[(~data_pd.userId.isin(cold_users)) | (data_pd.itemId.isin(popent_items))]\n",
    "# cold user(s) that have interacted with one or more of the shown items (if a cold user has not interacted with any of the shown items, it is not included in the test set)\n",
    "cold_users_interacted = np.array(data_pd[(data_pd.userId.isin(cold_users)) & (data_pd.itemId.isin(popent_items))]['userId'])\n",
    "test_pd = data_pd[(data_pd.userId.isin(cold_users_interacted)) & (~data_pd.itemId.isin(popent_items))]\n",
    "train = gl.SFrame(train_pd)\n",
    "test = gl.SFrame(test_pd)\n",
    "\n",
    "model = gl.factorization_recommender.create(train,user_id='userId',item_id='itemId',target='interaction',num_factors=i,regularization=j,linear_regularization=h,binary_target=True,max_iterations=50,random_seed=1,verbose=False)\n",
    "\n",
    "print('Rec sys built for popent strategy')\n",
    "\n",
    "rmse = model.evaluate_rmse(test,target='interaction')[\"rmse_overall\"]\n",
    "\n",
    "print('RMSE computed for popent strategy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rec sys built for error strategy\n",
      "RMSE computed for error strategy\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "45"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "writer.writerow([ranking_strategy,number_of_shown_items,nr_of_cold_users,rmse])\n",
    "\n",
    "\n",
    "# ERROR STRATEGY\n",
    "ranking_strategy = 'error strategy'\n",
    "# model is trained on all user item pairs of the warm users and the user item pairs of the cold user with the shown items (if the cold user has interacted with the shown items)\n",
    "train_pd = data_pd[(~data_pd.userId.isin(cold_users)) | (data_pd.itemId.isin(error_items))]\n",
    "# cold user(s) that have interacted with one or more of the shown items (if a cold user has not interacted with any of the shown items, it is not included in the test set)\n",
    "cold_users_interacted = np.array(data_pd[(data_pd.userId.isin(cold_users)) & (data_pd.itemId.isin(error_items))]['userId'])\n",
    "test_pd = data_pd[(data_pd.userId.isin(cold_users_interacted)) & (~data_pd.itemId.isin(error_items))]\n",
    "train = gl.SFrame(train_pd)\n",
    "test = gl.SFrame(test_pd)\n",
    "\n",
    "model = gl.factorization_recommender.create(train,user_id='userId',item_id='itemId',target='interaction',num_factors=i,regularization=j,linear_regularization=h,binary_target=True,max_iterations=50,random_seed=1,verbose=False)\n",
    "\n",
    "print('Rec sys built for error strategy')\n",
    "\n",
    "rmse = model.evaluate_rmse(test,target='interaction')[\"rmse_overall\"]\n",
    "\n",
    "print('RMSE computed for error strategy')\n",
    "\n",
    "writer.writerow([ranking_strategy,number_of_shown_items,nr_of_cold_users,rmse])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rec sys built for variance strategy\n",
      "RMSE computed for variance strategy\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "48"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# VARIANCE STRATEGY\n",
    "ranking_strategy = 'variance strategy'\n",
    "# model is trained on all user item pairs of the warm users and the user item pairs of the cold user with the shown items (if the cold user has interacted with the shown items)\n",
    "train_pd = data_pd[(~data_pd.userId.isin(cold_users)) | (data_pd.itemId.isin(variance_items))]\n",
    "# cold user(s) that have interacted with one or more of the shown items (if a cold user has not interacted with any of the shown items, it is not included in the test set)\n",
    "cold_users_interacted = np.array(data_pd[(data_pd.userId.isin(cold_users)) & (data_pd.itemId.isin(variance_items))]['userId'])\n",
    "test_pd = data_pd[(data_pd.userId.isin(cold_users_interacted)) & (~data_pd.itemId.isin(variance_items))]\n",
    "train = gl.SFrame(train_pd)\n",
    "test = gl.SFrame(test_pd)\n",
    "\n",
    "model = gl.factorization_recommender.create(train,user_id='userId',item_id='itemId',target='interaction',num_factors=i,regularization=j,linear_regularization=h,binary_target=True,max_iterations=50,random_seed=1,verbose=False)\n",
    "\n",
    "print('Rec sys built for variance strategy')\n",
    "\n",
    "rmse = model.evaluate_rmse(test,target='interaction')[\"rmse_overall\"]\n",
    "\n",
    "print('RMSE computed for variance strategy')\n",
    "\n",
    "writer.writerow([ranking_strategy,number_of_shown_items,nr_of_cold_users,rmse])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rec sys built for poperror strategy\n",
      "RMSE computed for poperror strategy\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "48"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#writer.writerow([ranking_strategy,number_of_shown_items,nr_of_cold_users,rmse])\n",
    "\n",
    "\n",
    "# POPERROR STRATEGY\n",
    "ranking_strategy = 'poperror strategy'\n",
    "# model is trained on all user item pairs of the warm users and the user item pairs of the cold user with the shown items (if the cold user has interacted with the shown items)\n",
    "train_pd = data_pd[(~data_pd.userId.isin(cold_users)) | (data_pd.itemId.isin(poperror_items))]\n",
    "# cold user(s) that have interacted with one or more of the shown items (if a cold user has not interacted with any of the shown items, it is not included in the test set)\n",
    "cold_users_interacted = np.array(data_pd[(data_pd.userId.isin(cold_users)) & (data_pd.itemId.isin(poperror_items))]['userId'])\n",
    "test_pd = data_pd[(data_pd.userId.isin(cold_users_interacted)) & (~data_pd.itemId.isin(poperror_items))]\n",
    "train = gl.SFrame(train_pd)\n",
    "test = gl.SFrame(test_pd)\n",
    "\n",
    "model = gl.factorization_recommender.create(train,user_id='userId',item_id='itemId',target='interaction',num_factors=i,regularization=j,linear_regularization=h,binary_target=True,max_iterations=50,random_seed=1,verbose=False)\n",
    "\n",
    "print('Rec sys built for poperror strategy')\n",
    "\n",
    "rmse = model.evaluate_rmse(test,target='interaction')[\"rmse_overall\"]\n",
    "\n",
    "print('RMSE computed for poperror strategy')\n",
    "\n",
    "writer.writerow([ranking_strategy,number_of_shown_items,nr_of_cold_users,rmse])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rec sys built for popvar strategy\n",
      "RMSE computed for popvar strategy\n"
     ]
    }
   ],
   "source": [
    "# POPVAR STRATEGY\n",
    "ranking_strategy = 'popvar strategy'\n",
    "# model is trained on all user item pairs of the warm users and the user item pairs of the cold user with the shown items (if the cold user has interacted with the shown items)\n",
    "train_pd = data_pd[(~data_pd.userId.isin(cold_users)) | (data_pd.itemId.isin(popvar_items))]\n",
    "# cold user(s) that have interacted with one or more of the shown items (if a cold user has not interacted with any of the shown items, it is not included in the test set)\n",
    "cold_users_interacted = np.array(data_pd[(data_pd.userId.isin(cold_users)) & (data_pd.itemId.isin(popvar_items))]['userId'])\n",
    "test_pd = data_pd[(data_pd.userId.isin(cold_users_interacted)) & (~data_pd.itemId.isin(popvar_items))]\n",
    "train = gl.SFrame(train_pd)\n",
    "test = gl.SFrame(test_pd)\n",
    "\n",
    "model = gl.factorization_recommender.create(train,user_id='userId',item_id='itemId',target='interaction',num_factors=i,regularization=j,linear_regularization=h,binary_target=True,max_iterations=50,random_seed=1,verbose=False)\n",
    "\n",
    "print('Rec sys built for popvar strategy')\n",
    "\n",
    "rmse = model.evaluate_rmse(test,target='interaction')[\"rmse_overall\"]\n",
    "\n",
    "print('RMSE computed for popvar strategy')\n",
    "\n",
    "writer.writerow([ranking_strategy,number_of_shown_items,nr_of_cold_users,rmse])\n",
    "\n",
    "csvfile.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "relecur",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
